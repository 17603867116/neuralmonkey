[train]
class=neuralmonkey.Experiment

name=translation

model=<run>
trainer=<trainer>

train_dataset=<train_data>
val_dataset=<val_data>

evaluation=[<bleuref>]

output=tests/tmp-test-output
overwrite_output_dir=True

epochs=1
random_seed=1234
logging_period=20
validation_period=60



[run]
class=neuralmonkey.Model

encoders=[<encoder>]
decoder=<decoder>

runner=<runner>

batch_size=16
postprocess=None





[bleuref]
class=evaluators.bleu_ref.BLEUReferenceImplWrapper
wrapper=lib/mteval/wrap-mteval.pl

[train_data]
; This is definition of the training data object. Notice that language are
; defined here, because they are used identifiers while preparing vocabularies.
; Dataset is not a standard class, it treats the __init__ methods arguements as
; a dictionary, therefore the data series names can be any strings.
class=config.utils.dataset_from_files
s_source=tests/data/train.tc.en
s_target=tests/data/train.tc.de
random_seed=1234

[val_data]
; Validation data, the languages are not necessary here, encoders and decoder
; acces the data series via the string identifiers defined here.
class=config.utils.dataset_from_files
s_source=tests/data/val.tc.en
s_target=tests/data/val.tc.de
random_seed=1234

[encoder_vocabulary]
class=config.utils.initialize_vocabulary
directory=tests/tmp-encoder-vocabulary
name=encoder_vocabulary
datasets=[<train_data>]
series_ids=[source]
max_size=25000

[encoder]
; This defines the sentence encoder object. All compulsory arguments from the
; __init__ methods must be defined in this block. The additional arguments may
; be defines, if they are not, the default value from the __init__ method is
; used. Notice the vocabulary is aquired via the language string.
class=encoders.sentence_encoder.SentenceEncoder
rnn_size=256
max_input_len=20
embedding_size=200
dropout_keep_p=0.5
attention_type=decoding_function.Attention
data_id=source
vocabulary=<encoder_vocabulary>

[decoder_vocabulary]
class=config.utils.initialize_vocabulary
directory=tests/tmp-decoder-vocabulary
name=decoder_vocabulary
datasets=[<train_data>]
series_ids=[target]
max_size=25000

[decoder]
class=decoders.decoder.Decoder
encoders=[<encoder>]
rnn_size=256
embedding_size=256
use_attention=True
dropout_keep_p=0.5
data_id=target
vocabulary=<decoder_vocabulary>

[trainer]
; This block just fills the arguments of the trainer __init__ method.
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
model=<run>
l2_regularization=1.0e-8

[runner]
; This is block is used for both validation and testing to run the model on
; given dataset.
class=runners.runner.GreedyRunner
batch_size=16
model=<run>
