[train]
class=entrypoints.experiment.Experiment
model=<run>
trainer=<trainer>
train_dataset=<train_data>
val_dataset=<val_data>
evaluation=[evaluators.bleu.bleu4]
output=tests/tmp-test-output
overwrite_output_dir=True
epochs=1
random_seed=1234
logging_period=20
validation_period=60
tfconfig=<tfconfig>
batch_size=16

[run]
class=entrypoints.model.Model
encoders=[<encoder>]
decoder=<decoder>
runner=<runner>
#postprocess=None
tfconfig=<tfconfig>

[tfconfig]
class=tensorflow.ConfigProto
inter_op_parallelism_threads=4
intra_op_parallelism_threads=4

[train_data]
class=config.utils.dataset_from_files
s_source=tests/data/train.tc.en
s_target=tests/data/train.tc.de
random_seed=1234

[val_data]
class=config.utils.dataset_from_files
s_source=tests/data/val.tc.en
s_target=tests/data/val.tc.de
random_seed=1234

[encoder_vocabulary]
class=config.utils.initialize_vocabulary
directory=tests/tmp-encoder-vocabulary
name=encoder_vocabulary
datasets=[<train_data>]
series_ids=[source]
max_size=25000

[encoder]
class=encoders.sentence_encoder.SentenceEncoder
rnn_size=256
max_input_len=20
embedding_size=200
dropout_keep_p=0.5
attention_type=decoding_function.Attention
data_id=source
vocabulary=<encoder_vocabulary>

[decoder_vocabulary]
class=config.utils.initialize_vocabulary
directory=tests/tmp-decoder-vocabulary
name=decoder_vocabulary
datasets=[<train_data>]
series_ids=[target]
max_size=25000

[decoder]
class=decoders.decoder.Decoder
encoders=[<encoder>]
rnn_size=256
embedding_size=256
use_attention=True
dropout_keep_p=0.5
data_id=target
vocabulary=<decoder_vocabulary>

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
l2_regularization=1.0e-8
decoder=<decoder>

[runner]
class=runners.runner.GreedyRunner
batch_size=16
decoder=<decoder>
